{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "outputLog = pandas.DataFrame(index = ['file', 'column', \"data type\", 'summary', 'missing values', 'length'])\n",
    "outputLog = outputLog.transpose()\n",
    "#import enchant\n",
    "def textUncleanCounter(column):\n",
    "    count = 0\n",
    "    for words in column:\n",
    "        #found way to count upper case via this stackoverflow post\n",
    "        #http://stackoverflow.com/questions/18129830/count-the-uppercase-letters-in-a-string\n",
    "        #compared number of upper case to\n",
    "        #print(words)\n",
    "        #is.nan doesn't work for strings so I have to handle it in here\n",
    "        #http://stackoverflow.com/questions/4843173/how-to-check-if-type-of-a-variable-is-string-in-python\n",
    "        #used same logic for isinstance when dealing with unicode stuff.\n",
    "        if(isinstance(words, str) or isinstance(words, unicode)):\n",
    "            if(sum(1 for c in words if c.isupper()) == len(words.split())):\n",
    "                count += 0\n",
    "            else:\n",
    "                count += 1\n",
    "        else:\n",
    "            #print(words)\n",
    "            if(np.isnan(words)):\n",
    "                count += 1\n",
    "            else:\n",
    "                count += 0\n",
    "    return(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleaniness(filePath, outputLog, csv = True, sheet = 2):\n",
    "    T = outputLog\n",
    "    if(csv):\n",
    "        data = pandas.read_csv(filePath)\n",
    "    else:\n",
    "        #FEC data we had was in XLS format, so we had to figure out how to import XLS data \n",
    "        #http://pandas.pydata.org/pandas-docs/stable/generated/pandas.ExcelFile.parse.html\n",
    "        data = pandas.ExcelFile(filePath)\n",
    "        data = data.parse(data.sheet_names[sheet-1])\n",
    "    data.count(axis = 1)\n",
    "    for column in data.columns:\n",
    "        #Pandas sets missing values to nan so I found an answer on a stackexchange post\n",
    "        #http://stackoverflow.com/questions/26266362/how-to-count-the-nan-values-in-the-column-in-panda-data-frame\n",
    "        summary = data[column].describe()\n",
    "        #print(data[column].dtype)\n",
    "        missingValue = (data[column].isnull().sum() + textUncleanCounter(data[column]))\n",
    "        #print(missingValue)\n",
    "        \n",
    "        columndata = (pandas.DataFrame(data = [filePath, column,data[column].dtype, summary, missingValue, len(data[column])],index = ['file', 'column',\"data type\", 'summary', 'missing values', 'length']))\n",
    "        T = T.append(columndata.transpose())\n",
    "    return(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"SP500HistoricalDataPart1.csv\", outputLog))\n",
    "#outputLog.to_csv(\"OutputLog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"SP500HistoricalDataPart2.csv\", outputLog))\n",
    "#outputLog.to_csv(\"OutputLog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"dJIndustialHistoricalData.csv\", outputLog))\n",
    "#outputLog.to_csv(\"OutputLog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"Sector base Indices/CBOE Gold Index.csv\", outputLog))\n",
    "#outputLog.to_csv(\"OutputLog.csv\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"Sector base Indices/NASDAQ Banking Index.csv\", outputLog))\n",
    "#outputLog.to_csv(\"OutputLog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"Sector base Indices/NASDAQ Biotechnology Index.csv\", outputLog))\n",
    "#outputLog.to_csv(\"OutputLog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"Sector base Indices/NASDAQ Industrial Index.csv\", outputLog))\n",
    "#outputLog.to_csv(\"OutputLog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"Sector base Indices/NYSE AMEX Oil Index.csv\", outputLog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NaN were messing up the basic analysis, so I had replaces them with zeros\n",
    "# I found out how from the pandas developer site\n",
    "#http://pandas.pydata.org/pandas-docs/stable/missing_data.html\n",
    "nytimesTemp = pandas.read_csv(\"NYTimes2014elections.csv\").fillna('00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#In order to actually evaluate the Nytimes I had to make changes to understand numeric data that was pulled as string\n",
    "#had to remove percentage sign from VotePercent columns\n",
    "#http://stackoverflow.com/questions/3559559/how-to-delete-a-character-from-a-string-using-python\n",
    "def floatConverter(column, percentSign = True): #If no percent sign then there is a comma\n",
    "    oldstr = column\n",
    "    #print(oldstr[10])\n",
    "    data = []\n",
    "    for cell in oldstr:\n",
    "        if(percentSign):\n",
    "            cellNoPercent = (cell[:-1])\n",
    "        else:\n",
    "            cellNoPercent = cell.replace(\",\", \"\")\n",
    "            #If there wasn't percent then they were whole numbers, many of which had \n",
    "        data.append(cellNoPercent)\n",
    "    #Iterating and changing to floats wasnt working, so I found a method to do it to a list post cleaning        \n",
    "    #http://stackoverflow.com/questions/4004550/converting-string-series-to-float-list-in-python\n",
    "    \n",
    "    return([float(x) for x in data])    \n",
    "    \n",
    "nytimesTemp['VotePercent1'] = floatConverter(nytimesTemp['VotePercent1'])\n",
    "nytimesTemp['VotePercent2'] = floatConverter(nytimesTemp['VotePercent2'])\n",
    "nytimesTemp['VotePercent3'] = floatConverter(nytimesTemp['VotePercent3'])\n",
    "nytimesTemp['VotePercent4'] = floatConverter(nytimesTemp['VotePercent4'])\n",
    "nytimesTemp['VotePercent5'] = floatConverter(nytimesTemp['VotePercent5'])\n",
    "nytimesTemp['VotePercent6'] = floatConverter(nytimesTemp['VotePercent6'])\n",
    "nytimesTemp['VotePercent7'] = floatConverter(nytimesTemp['VotePercent7'])\n",
    "nytimesTemp['VotePercent8'] = floatConverter(nytimesTemp['VotePercent8'])\n",
    "nytimesTemp['VotePercent9'] = floatConverter(nytimesTemp['VotePercent9'])\n",
    "nytimesTemp['VotePercent10'] = floatConverter(nytimesTemp['VotePercent10'])\n",
    "nytimesTemp['VotePercent11'] = floatConverter(nytimesTemp['VotePercent11'])\n",
    "nytimesTemp['VotePercent12'] = floatConverter(nytimesTemp['VotePercent12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nytimesTemp['Votes1'] = floatConverter(nytimesTemp['Votes1'],percentSign = False)\n",
    "nytimesTemp['Votes2'] = floatConverter(nytimesTemp['Votes2'],percentSign = False)\n",
    "nytimesTemp['Votes3'] = floatConverter(nytimesTemp['Votes3'],percentSign = False)\n",
    "nytimesTemp['Votes4'] = floatConverter(nytimesTemp['Votes4'],percentSign = False)\n",
    "nytimesTemp['Votes5'] = floatConverter(nytimesTemp['Votes5'],percentSign = False)\n",
    "nytimesTemp['Votes6'] = floatConverter(nytimesTemp['Votes6'],percentSign = False)\n",
    "nytimesTemp['Votes7'] = floatConverter(nytimesTemp['Votes7'],percentSign = False)\n",
    "nytimesTemp['Votes8'] = floatConverter(nytimesTemp['Votes8'],percentSign = False)\n",
    "nytimesTemp['Votes9'] = floatConverter(nytimesTemp['Votes9'],percentSign = False)\n",
    "nytimesTemp['Votes10'] = floatConverter(nytimesTemp['Votes10'],percentSign = False)\n",
    "nytimesTemp['Votes11'] = floatConverter(nytimesTemp['Votes11'],percentSign = False)\n",
    "nytimesTemp['Votes12'] = floatConverter(nytimesTemp['Votes12'],percentSign = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nytimesTemp = nytimesTemp.replace('0', np.nan)\n",
    "nytimesTemp = nytimesTemp.replace('00', np.nan)\n",
    "nytimesTemp = nytimesTemp.replace(0, np.nan)\n",
    "nytimesTemp.to_csv(\"nytimesTemps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"nytimesTemps.csv\", outputLog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"FEC Elections Data/2004congresults.xls\", outputLog, csv = False, sheet = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"FEC Elections Data/2008congresults.xls\", outputLog, csv = False, sheet = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"FEC Elections Data/2012congresults.xls\", outputLog, csv = False, sheet = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputLog = outputLog.append(cleaniness(\"Contributions by Industry 2012-2014.csv\", outputLog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I had a bunch of duplicating rows so I decided it would be easier to dedup. \n",
    "#It's probably costing me time but fixing function might take longer.\n",
    "#http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop_duplicates.html\n",
    "#http://stackoverflow.com/questions/26469551/drop-duplicates-within-a-set\n",
    "outputLog = outputLog.drop_duplicates(['file','column'])\n",
    "outputLog.to_csv(\"Cleaning Analysis output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
