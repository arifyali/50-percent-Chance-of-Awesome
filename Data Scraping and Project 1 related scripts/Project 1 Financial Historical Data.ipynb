{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In accordance with the class policies and Georgetown's Honor Code,\n",
    "# I certify that, with the exceptions of the lecture notes and those\n",
    "# items noted below, this work is my own. I know that I can speak to\n",
    "# others about my code, but I cannot share the code itself.\n",
    "# If I received any help, I have noted it\n",
    "\n",
    "import json#I ended up on needing this packages after finding out the API can output CSVs\n",
    "import requests#I ended up on needing this packages after finding out the API can output CSVs\n",
    "import urllib2#I ended up on needing this packages after finding out the API can output CSVs\n",
    "import pandas\n",
    "import csv#I thought I might need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quandl (the website used) required I use tickers and provided a csv with the tickers\n",
    "dJIndustial = pandas.read_csv(\"dowjonesIA.csv\")\n",
    "##In hindsight, dJIndustial['Ticker'] would have been good enough\n",
    "dJIndustialTickers = (dJIndustial['Ticker']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##I needed to set a base data case for my loop, therefore I look the first stock to set up the Pandas DataFrame\n",
    "##The URL is set up based on the API info from Quandl. \n",
    "url = 'https://www.quandl.com/api/v3/datasets/YAHOO/'+dJIndustialTickers[0]+'.csv?api_key=p3bC2cMj_FbQGSDDjs4y'\n",
    "data = pandas.read_csv(url)\n",
    "#http://stackoverflow.com/questions/26763344/convert-pandas-column-to-datetime\n",
    "#I had to subset data by date, so I needed to convert DataFrame column to Dates\n",
    "data['Date']= pandas.to_datetime(data['Date'])\n",
    "#I needed to create a datetime that Pandas would recognize so under Time Stamps I found it \n",
    "#http://pandas.pydata.org/pandas-docs/stable/timeseries.html\n",
    "#We were able to obtain election data from 2004, so I grabs corresponding stock data\n",
    "data = data.loc[(data.Date >pandas.datetime(2004,1,1))]\n",
    "#good way of knowing the companies of data Im collecting is using tickers to identify\n",
    "data['ticker'] = dJIndustialTickers[0] \n",
    "#feature 1\n",
    "data['price change'] = data['Close'] - data['Open']\n",
    "#feature 2\n",
    "data['percentage change'] = data['price change']/data['Open']\n",
    "#feature 3\n",
    "data['Opening Total Value'] = data['Open']*data['Volume']\n",
    "#feature 4\n",
    "data['Closing Total Value'] = data['Close']*data['Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#In reality, I should have made this a function, but I was a bit overworked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BA\n",
      "CAT\n",
      "CSCO\n",
      "CVX\n",
      "DD\n",
      "DIS\n",
      "GE\n",
      "GS\n",
      "HD\n",
      "IBM\n",
      "INTC\n",
      "JNJ\n",
      "JPM\n",
      "KO\n",
      "MCD\n",
      "MMM\n",
      "MRK\n",
      "MSFT\n",
      "NKE\n",
      "PFE\n",
      "PG\n",
      "T\n",
      "TRV\n",
      "UNH\n",
      "UTX\n",
      "V\n",
      "VZ\n",
      "WMT\n"
     ]
    }
   ],
   "source": [
    "#For Loop, basically every thing from the base.\n",
    "for ticker in dJIndustialTickers[1:(len(dJIndustialTickers)-1)]:\n",
    "    url = 'https://www.quandl.com/api/v3/datasets/YAHOO/'+ticker+'.csv?api_key=p3bC2cMj_FbQGSDDjs4y'\n",
    "    company = pandas.read_csv(url)\n",
    "    company['Date']= pandas.to_datetime(company['Date'])\n",
    "    company = company.loc[(company.Date >pandas.datetime(2004,1,1))]\n",
    "    company['ticker'] = ticker\n",
    "    company['price change'] = company['Open'] - company['Close']\n",
    "    company['percentage change'] = company['price change']/company['Open']\n",
    "    company['Opening Total Value'] = company['Open']*company['Volume']\n",
    "    company['Closing Total Value'] = company['Close']*company['Volume']\n",
    "    print(ticker)\n",
    "    data = data.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"dJIndustialHistoricalData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#followed through on hindsight \n",
    "sNP500 = pandas.read_csv(\"SP500.csv\")\n",
    "sNP500Tickers = sNP500['Ticker']\n",
    "#SP 500 had sector in the quandl provided csv, so I included it\n",
    "sNP500Sector = sNP500['Sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#did sNP500Tickers[0] first, as part of the base idea\n",
    "url = 'https://www.quandl.com/api/v3/datasets/YAHOO/'+sNP500Tickers[0]+'.csv?api_key=p3bC2cMj_FbQGSDDjs4y'\n",
    "data = pandas.read_csv(url)\n",
    "data['Date']= pandas.to_datetime(data['Date'])\n",
    "data = data.loc[(data.Date >pandas.datetime(2004,1,1))]\n",
    "data['ticker'] = sNP500Tickers[0] \n",
    "data['Sector'] = sNP500Sector[0]\n",
    "data['price change'] = data['Close'] - data['Open']\n",
    "data['percentage change'] = data['price change']/data['Open']\n",
    "data['Opening Total Value'] = data['Open']*data['Volume']\n",
    "data['Closing Total Value'] = data['Close']*data['Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I kept getting strange no response call errors so I limited the range\n",
    "for i in range(1, 250):\n",
    "    url = 'https://www.quandl.com/api/v3/datasets/YAHOO/'+sNP500Tickers[i]+'.csv?api_key=p3bC2cMj_FbQGSDDjs4y'\n",
    "    #ran into errors when certain stock data was taken out, so I added try \n",
    "    #so for loop wouldn't break\n",
    "    try:\n",
    "        company = pandas.read_csv(url)\n",
    "        company['Date']= pandas.to_datetime(company['Date'])\n",
    "        company = company.loc[(company.Date >pandas.datetime(2004,1,1))]\n",
    "        company['ticker'] = sNP500Tickers[i] \n",
    "        company['Sector'] = sNP500Sector[i]\n",
    "        company['price change'] = company['Open'] - company['Close']\n",
    "        company['percentage change'] = company['price change']/company['Open']\n",
    "        company['Opening Total Value'] = company['Open']*company['Volume']\n",
    "        company['Closing Total Value'] = company['Close']*company['Volume']\n",
    "\n",
    "        data = data.append(company)\n",
    "    except:\n",
    "        #I wanted to know what and how many stocks failed\n",
    "        print(sNP500Tickers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"SP500HistoricalDataPart1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Another For loop base\n",
    "url = 'https://www.quandl.com/api/v3/datasets/YAHOO/'+sNP500Tickers[250]+'.csv?api_key=p3bC2cMj_FbQGSDDjs4y'\n",
    "data = pandas.read_csv(url)\n",
    "data['Date']= pandas.to_datetime(data['Date'])\n",
    "data = data.loc[(data.Date >pandas.datetime(2004,1,1))]\n",
    "data['ticker'] = sNP500Tickers[0] \n",
    "data['Sector'] = sNP500Sector[0]\n",
    "data['price change'] = data['Close'] - data['Open']\n",
    "data['percentage change'] = data['price change']/data['Open']\n",
    "data['Opening Total Value'] = data['Open']*data['Volume']\n",
    "data['Closing Total Value'] = data['Close']*data['Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAVI\n"
     ]
    }
   ],
   "source": [
    "##picked up remaining S&P 500\n",
    "for i in range(251, (len(sNP500)-1)):\n",
    "    url = 'https://www.quandl.com/api/v3/datasets/YAHOO/'+sNP500Tickers[i]+'.csv?api_key=p3bC2cMj_FbQGSDDjs4y'\n",
    "    try:\n",
    "        company = pandas.read_csv(url)\n",
    "        company['Date']= pandas.to_datetime(company['Date'])\n",
    "        company = company.loc[(company.Date >pandas.datetime(2004,1,1))]\n",
    "        company['ticker'] = sNP500Tickers[i] \n",
    "        company['Sector'] = sNP500Sector[i]\n",
    "        company['price change'] = company['Open'] - company['Close']\n",
    "        company['percentage change'] = company['price change']/company['Open']\n",
    "        company['Opening Total Value'] = company['Open']*company['Volume']\n",
    "        company['Closing Total Value'] = company['Close']*company['Volume']\n",
    "\n",
    "        data = data.append(company)\n",
    "    except:\n",
    "        print(sNP500Tickers[i])\n",
    "        #after finishing, it turns out only stock I couldn't get was NAVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"SP500HistoricalDataPart2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
