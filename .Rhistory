vb = backtracking(f,vb,df(vb),solve(d2f(vb),-df(vb)),0.01,0.5);
}
print(vb[1]^2+vb[2]^2)
print(vb)
}
xbnds = c(-5,5);
ybnds = (vb[3]-(vb[1]*xbnds))/vb[2];
lines(xbnds,ybnds,lty=2,col='green')
matrix(c(1,2,3,4), 2)
library(e1071)
load("Dropbox/School/Georgetown/Analytics 561 Fall 2015/HW07/mnist01_testX.Rdata")
load("Dropbox/School/Georgetown/Analytics 561 Fall 2015/HW07/mnist01_testy.Rdata")
m=svm(testX,testy,kernel='linear')
filled.contour(matrix(t(m$coefs) %*% m$SV,nrow=28,ncol=28),col=heat.colors(10),nlevels=10)
## Part B ##
p=predict(m,testX)
matrix(c(sum(testy[p<0]==0), sum(testy[p>0]==0),
sum(testy[p<0]==1), sum(testy[p>0]==1)),
2)
t_formula_confidence_interval = function(xhat, SD, ciLevel, sample_size){
t_score = qt(1-((1-ciLevel)/2), sample_size-1)
SE = SD/sqrt(sample_size)
return(c(xhat - t_score*SE, xhat + t_score*SE))
}
t_formula_confidence_interval(18.5, 5, .90, 20)
Spruce <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/Spruce.csv")
boxplot(Spruce$Ht.change)
hist(Spruce$Ht.change, breaks = 20)
t_formula_confidence_interval(mean(Spruce$Ht.change), sd(Spruce$Ht.change), .95, length(Spruce$Ht.change))
t_formula_confidence_interval(18.5, 5, .90, 20)
?t.test
xhat = 5.8; yhat = 1.9
sdx = 8.6; sdy = 4.2
sizex = 43; sizey = 36
sdxy = sqrt(sdx^2/sizex+sdy^2/sizey)
df = (sdx^2/sizex + sdy^2/sizey)^2/
((sdx^2/sizex)^2/(sizex-1)+(sdy^2/sizey)^2/(sizey-1))
t_score = qt(1-((1-.95)/2), df)
t_score
(xhat-yhat)+c(t_score, -t_score)*sdxy
(xhat-yhat)+c(-t_score, t_score)*sdxy
df
df = ceiling((sdx^2/sizex + sdy^2/sizey)^2/
((sdx^2/sizex)^2/(sizex-1)+(sdy^2/sizey)^2/(sizey-1)))
t_score = qt(1-((1-.95)/2), df)
(xhat-yhat)+c(-t_score, t_score)*sdxy
df
Girls2004 <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/Girls2004.csv")
View(Girls2004)
View(Girls2004)
boxplot(Girls2004$Weight[Girls2004$Smoker=="No"]~Girls2004$Weight[Girls2004$Smoker=="Yes"])
boxplot(Girls2004$Weight[Girls2004$Smoker=="No"])
boxplot(Girls2004$Weight[Girls2004$Smoker=="Yes"])
boxplot(Girls2004$Weight[Girls2004$Smoker=="No"])
boxplot(Girls2004$Weight[Girls2004$Smoker=="Yes"])
par(mfrow=c(1,2))
boxplot(Girls2004$Weight[Girls2004$Smoker=="No"])
boxplot(Girls2004$Weight[Girls2004$Smoker=="Yes"])
boxplot(Girls2004$Weight[Girls2004$Smoker=="No"], main = "Nonsmoker")
boxplot(Girls2004$Weight[Girls2004$Smoker=="Yes"], main = "smoker")
hist(Girls2004$Weight[Girls2004$Smoker=="No"], main = "Nonsmoker")
hist(Girls2004$Weight[Girls2004$Smoker=="Yes"], main = "smoker")
hist(Girls2004$Weight[Girls2004$Smoker=="No"], main = "Nonsmoker", breaks = 10)
hist(Girls2004$Weight[Girls2004$Smoker=="Yes"], main = "smoker", breaks = 10)
qqplot(Girls2004$Weight[Girls2004$Smoker=="No"], main = "Nonsmoker")
qqnorm()
?qqnorm
qqnorm(Girls2004$Weight[Girls2004$Smoker=="No"], main = "Nonsmoker")
qqnorm(Girls2004$Weight[Girls2004$Smoker=="Yes"], main = "smoker")
?qqline
qqline(Girls2004$Weight[Girls2004$Smoker=="No"])
qqnorm(Girls2004$Weight[Girls2004$Smoker=="No"], main = "Nonsmoker")
qqline(Girls2004$Weight[Girls2004$Smoker=="No"])
qqline(Girls2004$Weight[Girls2004$Smoker=="Yes"])
qqnorm(Girls2004$Weight[Girls2004$Smoker=="No"], main = "Nonsmoker")
qqline(Girls2004$Weight[Girls2004$Smoker=="No"])
qqnorm(Girls2004$Weight[Girls2004$Smoker=="Yes"], main = "smoker")
qqline(Girls2004$Weight[Girls2004$Smoker=="Yes"])
qqnorm(Girls2004$Weight[Girls2004$Smoker=="No"], main = "Nonsmoker")
qqline(Girls2004$Weight[Girls2004$Smoker=="No"])
qqnorm(Girls2004$Weight[Girls2004$Smoker=="Yes"], main = "smoker")
qqline(Girls2004$Weight[Girls2004$Smoker=="Yes"])
xhat = mean(Girls2004$Weight[Girls2004$Smoker=="No"])
yhat = mean(Girls2004$Weight[Girls2004$Smoker=="Yes"])
sdx = sd(Girls2004$Weight[Girls2004$Smoker=="No"])
sdy = sd(Girls2004$Weight[Girls2004$Smoker=="Yes"])
sizex = length(Girls2004$Weight[Girls2004$Smoker=="No"])
sizey = length(Girls2004$Weight[Girls2004$Smoker=="Yes"])
sdxy = sqrt(sdx^2/sizex+sdy^2/sizey)
df = (sdx^2/sizex + sdy^2/sizey)^2/
((sdx^2/sizex)^2/(sizex-1)+(sdy^2/sizey)^2/(sizey-1))
t_score = qt(1-((1-.95)/2), df)
(xhat-yhat)+c(-t_score, t_score)*sdxy
df
t_score = qt(1-((1-.95)/2), 15)
(xhat-yhat)+c(-t_score, t_score)*sdxy
((sdx^2/sizex)^2/(sizex-1)+(sdy^2/sizey)^2/(sizey-1))
t_score = qt(1-((1-.95)/2), df)
(xhat-yhat)+c(-t_score, t_score)*sdxy
?prop.test
GSS2002 <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/GSS2002.csv")
View(GSS2002)
table(GSS2002$Pres00)
prop.test(426, 980)
prop.test(426, 980)$conf.int
prop.test(426, 980, correct = F)$conf.int
prop.test(459, 980, correct = F)$conf.int
prop.test(426, 759, correct = F)$conf.int
prop.test(459-426, 980-759,correct = F)$conf.int
prop.test(c(459,426), c(980,759),correct = F)$conf.int
@
Verizon <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/Verizon.csv")
View(Verizon)
ILEC = Verizon[Verizon$Group=="ILEC",]
View(Verizon)
ILEC = Verizon[Verizon$Group=="ILEC","Time"]
CLEC = Verizon[Verizon$Group=="CLEC","Time"]
t_formula_confidence_interval(mean(ILEC),sd(ILEC),.95,length(ILEC))
ILEC = Verizon[Verizon$Group=="ILEC","Time"]
aa= t.test(ILEC)
aa$conf.int
CLEC = Verizon[Verizon$Group=="CLEC","Time"]
t.test(CLEC)$conf.int
ILEC = Verizon[Verizon$Group=="ILEC","Time"]
alpha = .95
z <- replicate(10000,mean(sample(ILEC,size = length(ILEC), replace = T)))
# confidence interval
quantile(z,c((1-alpha)/2,(1+alpha)/2))
t.test(ILEC)$conf.int
CLEC = Verizon[Verizon$Group=="CLEC","Time"]
alpha = .95
z <- replicate(10000,mean(sample(CLEC,size = length(CLEC), replace = T)))
# confidence interval
quantile(z,c((1-alpha)/2,(1+alpha)/2))
t.test(CLEC)$conf.int
Girls2004 <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/Girls2004.csv")
xhat = mean(Girls2004$Weight[Girls2004$Smoker=="No"])
yhat = mean(Girls2004$Weight[Girls2004$Smoker=="Yes"])
sdx = sd(Girls2004$Weight[Girls2004$Smoker=="No"])
sdy = sd(Girls2004$Weight[Girls2004$Smoker=="Yes"])
sizex = length(Girls2004$Weight[Girls2004$Smoker=="No"])
sizey = length(Girls2004$Weight[Girls2004$Smoker=="Yes"])
sdxy = sqrt(sdx^2/sizex+sdy^2/sizey)
df = (sdx^2/sizex + sdy^2/sizey)^2/
((sdx^2/sizex)^2/(sizex-1)+(sdy^2/sizey)^2/(sizey-1))
t_score = qt(1-((1-.95)/2), df)
(xhat-yhat)-t_score*sdxy
Verizon <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/Verizon.csv")
ILEC = Verizon[Verizon$Group=="ILEC","Time"]
alpha = .95
z <- replicate(10000,mean(sample(ILEC,size = length(ILEC), replace = T)))
# confidence interval
quantile(z,c((1-alpha)/2,(1+alpha)/2))
t.test(ILEC)$conf.int
alpha = .95
z <- replicate(10000,mean(sample(ILEC,size = length(ILEC), replace = T)))
# confidence interval
quantile(z,c((1-alpha)/2,(1+alpha)/2))
t.test(ILEC)$conf.int
t.test(ILEC)$conf.int[[1]]
t.test(ILEC)$conf.int[[2]]
t.test(ILEC)$conf.int[1]
Spruce <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/Spruce.csv")
boxplot(Spruce$Ht.change)
hist(Spruce$Ht.change, breaks = 20)
t_formula_confidence_interval(mean(Spruce$Ht.change), sd(Spruce$Ht.change), .95, length(Spruce$Ht.change))
t_formula_confidence_interval = function(xhat, SD, ciLevel, sample_size){
t_score = qt(1-((1-ciLevel)/2), sample_size-1)
SE = SD/sqrt(sample_size)
return(c(xhat - t_score*SE, xhat + t_score*SE))
}
t_formula_confidence_interval(18.05, 5, .90, 20)
Spruce <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/Spruce.csv")
par(mfrow=c(1,2))
boxplot(Spruce$Ht.change)
hist(Spruce$Ht.change, breaks = 20)
qqnorm(Spruce$Ht.change)
qqline(Spruce$Ht.change)
Spruce <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/Spruce.csv")
t_formula_confidence_interval(mean(Spruce$Ht.change), sd(Spruce$Ht.change), .95, length(Spruce$Ht.change))
xhat = 5.8; yhat = 1.9
sdx = 8.6; sdy = 4.2
sizex = 43; sizey = 36
sdxy = sqrt(sdx^2/sizex+sdy^2/sizey)
df = (sdx^2/sizex + sdy^2/sizey)^2/
((sdx^2/sizex)^2/(sizex-1)+(sdy^2/sizey)^2/(sizey-1))
t_score = qt(1-((1-.95)/2), df)
(xhat-yhat)+c(-t_score, t_score)*sdxy
par(mfrow=c(1,2))
boxplot(Girls2004$Weight[Girls2004$Smoker=="No"], main = "Nonsmoker")
boxplot(Girls2004$Weight[Girls2004$Smoker=="Yes"], main = "smoker")
hist(Girls2004$Weight[Girls2004$Smoker=="No"], main = "Nonsmoker", breaks = 10)
hist(Girls2004$Weight[Girls2004$Smoker=="Yes"], main = "smoker", breaks = 10)
qqnorm(Girls2004$Weight[Girls2004$Smoker=="No"], main = "Nonsmoker")
qqline(Girls2004$Weight[Girls2004$Smoker=="No"])
qqnorm(Girls2004$Weight[Girls2004$Smoker=="Yes"], main = "smoker")
qqline(Girls2004$Weight[Girls2004$Smoker=="Yes"])
prop.test(459, 980, correct = F)$conf.int
prop.test(426, 759, correct = F)$conf.int
prop.test(c(459,426), c(980,759),correct = F)$conf.int
Verizon <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/Verizon.csv")
ILEC = Verizon[Verizon$Group=="ILEC","Time"]
alpha = .95
z <- replicate(10000,mean(sample(ILEC,size = length(ILEC), replace = T)))
# confidence interval
quantile(z,c((1-alpha)/2,(1+alpha)/2))
t.test(ILEC)$conf.int
9.117945-7.705276
9.144520-7.729224
1.412669>1.415296
CLEC = Verizon[Verizon$Group=="CLEC","Time"]
alpha = .95
z <- replicate(10000,mean(sample(CLEC,size = length(CLEC), replace = T)))
# confidence interval
quantile(z,c((1-alpha)/2,(1+alpha)/2))
t.test(CLEC)$conf.int
length(CLEC)
install.packages(c('rzmq','repr','IRkernel','IRdisplay'),
repos = c('http://irkernel.github.io/', getOption('repos')))
r <- getOption('repos')
r$IRkernel <- 'http://irkernel.github.io/'
options(repos = r)
update.packages(repos = c('http://irkernel.github.io/', getOption('repos')))
install.packages(c("caret", "class", "curl", "foreign", "jsonlite", "manipulate", "MASS", "Matrix", "mgcv", "nlme", "nnet", "Rcpp", "spatial", "stringi", "testthat"))
update.packages(repos = c('http://irkernel.github.io/', getOption('repos')))
IRkernel::installspec()
Sodor.kidstemp = c(98.0, 98.9, 99.0, 98.9, 98.8, 98.6, 99.1, 98.9, 98.5, 98.9, 98.9, 98.4, 99.0, 99.2, 98.6, 98.8, 98.9, 98.7)
mean(Sodor.kidstemp)
sd(Sodor.kidstemp)
t = (mean(Sodor.kidstemp)-98.6)/
(sd(Sodor.kidstemp)/sqrt(length(Sodor.kidstemp)))
t
qt(t, df = length(Sodor.kidstemp)-1)
pt(t, df = length(Sodor.kidstemp)-1)
pt(t, df = length(Sodor.kidstemp)-1, lower.tail = F)
?qt
Sodor.kidstemp.ci = replicate(10000, mean(sample(Sodor.kidstemp, length(Sodor.kidstemp), replace = T)))
quantile(Sodor.kidstemp.ci, c(0.025,0.975))
?prop.test
prop.test(c(28,13), c(250, 250), correct = F)
prop.test(c(28,13), c(250, 250), correct = F, alternative = "less")
prop.test(c(28,13), c(250, 250), correct = F, alternative = "greater")
load("~/Documents/Analytics 561 Video Project/Make it Rain/Rainingdata.RData")
?vline
?vbline
?abline
?curve
curve(y~2*x^.25)
curve(y~2*x^.25, 0, 1)
log.likelhood = function(x){2*x^(1/4)}
curve(log.likelhood)
h0 = function(x){1/2*x^(-1/2)}
curve(h0)
?curve
log.likelhood = function(x){2*x^(1/4)}
curve(log.likelhood)
h0 = function(x){1/2*x^(-1/2)}
curve(h0, add = T)
log.likelhood = function(x){2*x^(1/4)}
curve(log.likelhood)
h0 = function(x){1/2*x^(-1/2)}
curve(h0, add = T, col = "blue")
ha = function(x){1/4*x^(-3/4)}
curve(ha, add = T, col = "red")
NCBirths2004 <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/NCBirths2004.csv")
part_b = lm(Weight~Gestation, data = NCBirths2004)
summary(part_b)$coefficients[,2][2]
nrow(NCBirths2004)
sqrt(nrow(NCBirths2004))
summary(part_b)$coefficients[,2][2]*sqrt(nrow(NCBirths2004))
summary(part_b)$coefficients
summary(part_b)
aa= summary(part_b)
aa$residuals
aa
aa$fstatistic
aa$cov.unscaled
aa$terms
aa$aliased
aa$fstatistic
aa
summary(part_b)
aa$coefficients
Volleyball2009 <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/Volleyball2009.csv")
plot(Kills~Assts, data = Volleyball2009)
@
There seems to be a positive relationship between Kills and Assts. This is based on a pattern that could be fitted to a line with a positive slope.
\subsection*{Part B}
library(knitr)
opts_knit$set(concordance=TRUE)
opts_chunk$set(background="white", highlight=FALSE, fig.keep="high", out.width="0.33\\linewidth")
part_b = lm(Kills~Assts, data = Volleyball2009)
part_b$coefficients
summary(part_b)$r.squared
plot(Volleyball2009$Assts, resid(part_b), ylab = "Residuals")
abline(h=0)
lines(smooth.spline(Volleyball2009$Assts, resid(part_b), df = 3),
col="blue")
FlightDelays <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/FlightDelays.csv")
FlightDelays$Carrier = as.character(FlightDelays$Carrier)
boxplot(Delay~Carrier, data = FlightDelays)
hist(FlightDelays$Delay[FlightDelays$Carrier=="AA"])
hist(FlightDelays$Delay[FlightDelays$Carrier=="UA"])
qqnorm(FlightDelays$Delay[FlightDelays$Carrier=="AA"])
qqnorm(FlightDelays$Delay[FlightDelays$Carrier=="UA"])
gaussProb = function(x,mu,Sig) {
return (exp(-t(x-mu)%*% solve(Sig,x-mu)/2)/((2*pi*sqrt(det(Sig)))^(length(x)/2)));
}
n = 1000;
p = c(0.75,0.25); # This is the "alpha" parameter
# Declaration of the parameters for the Gaussian components:
mu1 = c(-2,1);
S1 = rbind(c(2,-1),c(-1,2));
Sigma1 = S1 %*% S1;
mu2 = c(1,0.25);
S2 = rbind(c(0.25,0),c(0,0.25));
Sigma2 = S2 %*% S2;
X=c();
for (i in 1:n) {
j = sample(c(1,2),1,prob=p);
if (j == 1) {
X=cbind(X,S1%*%rnorm(2)+mu1)
}
if (j == 2) {
X=cbind(X,S2%*%rnorm(2)+mu2)
}
}
res = 32;
t1 = seq(-10,2,length=res);
t2 = seq(-5,10,length=res);
plot(X[1,],X[2,],col='orange',xlim=c(-10,2),ylim=c(-5,10),main="GMM Samples")
# Random initialization
a1 = 0.5;
a2 = 0.4;
j = sample(1:n,1);
m1=X[,j]
j = sample(1:n,1);
m2=X[,j]
sig1 = matrix(rnorm(4),2,2);
sig1 = sig1 %*% t(sig1);
sig2 = matrix(rnorm(4),2,2);
sig2 = sig2 %*% t(sig2);
q = matrix(0,2,n); # Container for the conditional probabilities
for (iter in 1:20) {
# The E-step
for (i in 1:n) {
q[1,i] = a1 * gaussProb(X[,i],m1,sig1);
q[2,i] = a2 * gaussProb(X[,i],m2,sig2);
}
for (i in 1:n) {
z = sum(q[,i]);
q[1,i] = q[1,i]/z;
q[2,i] = q[2,i]/z;
}
# The M-step updates
a1 = sum(q[1,])/sum(q);
a2 = sum(q[2,])/sum(q);
m1 = c(sum(X[1,]*q[1,]),sum(X[2,]*q[1,]))/sum(q[1,]);
m2 = c(sum(X[1,]*q[2,]),sum(X[2,]*q[2,]))/sum(q[2,]);
sig1[,]=0;
for (i in 1:n) {
sig1 = sig1+q[1,i]*(X[,i]-m1)%o%(X[,i]-m1);
}
sig1 = sig1 / sum(q[1,]);
sig2[,]=0;
for (i in 1:n) {
sig2 = sig2+q[2,i]*(X[,i]-m2)%o%(X[,i]-m2);
}
sig2 = sig2 / sum(q[2,]);
print(c(a1,a2));
print(c(m1,m2));
print(sig1);
print(sig2);
Z=matrix(0,res,res);
for (i in 1:res) {
for (j in 1:res) {
v=c(t1[i],t2[j])
Z[i,j] = a1*gaussProb(v,m1,sig1)+a2*gaussProb(v,m2,sig2)
}
}
filled.contour(t1,t2,Z,main=paste("EM Iteration ",iter))
}
load("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/final.rdata")
load("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/final.rdata")
hist(problem1)
load("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/final.rdata")
mean(problem1)
mean(problem1)
var(problem1)
var(problem1)-mean(problem1)
sqrt(var(problem1)-mean(problem1))
View(problem5)
mean(problem5$A==0)
mean(problem1$A==1)
mean(problem5$A==1)
mean(problem5$B[problem5$A==1]==1)
mean(problem5$B[problem5$A==0]==1)
?chisq.test
chisq.test(problem5$B, problem5$C)
chisq.test(problem5$A, problem5$D)
mean(problem5$D[problem5$B==1 & problem5$C==0]==1)
partC = table(problem5$B, problem5$C)
chisq.test(partC)
partD = table(problem5$A, problem5$D)
chisq.test(partD)
chisq.test(partC)
mean((problem5$B[problem5$A==1])==1)
mean((problem5$B[problem5$A==0])==1)
17-NULL
Volleyball2009 <- read.csv("~/Dropbox/School/Georgetown/Analytics 511 Fall 2015/ChiharaHesterberg/Volleyball2009.csv")
summary(Volleyball2009)
summary(table(Volleyball2009))
?t.test
Problem63 = matrix(c(23, 18,7,13),2)
Problem63.prop = prop.test(Problem63)
Problem63.prop
prop.test(459, 980, correct = F)
setwd("~/Documents/Analytics 501 Fall 2015/50-percent-Chance-of-Awesome/")
political_data = read.csv("part2_exploratory_analysis/Datasets/PoldataSPIndustries.csv")
political_data_short = political_data[!duplicated(political_data[, c("YEAR", "STATE", "FIRST", "LAST", "DISTRICT", "PARTY")]),]
unique(political_data_short$PARTY)
unique(political_data_short$WINNER)
unique(political_data_short$INCUMBENT)
library(e1071)
?svm
political_data_short$ID = (political_data_short$WINNER)
political_data_short$PARTY[political_data_short$PARTY==R] = 1
political_data_short$PARTY[political_data_short$PARTY=="R"] = 1
political_data_short$PARTY = as.character(political_data_short$PARTY)
political_data_short$PARTY[political_data_short$PARTY=="R"] = 1
political_data_short$PARTY[political_data_short$PARTY=="D"] = 2
political_data_short = political_data[!duplicated(political_data[, c("YEAR", "STATE", "FIRST", "LAST", "DISTRICT", "PARTY")]),]
political_data_short$ID = (political_data_short$WINNER)
political_data_short$PARTY = as.character(political_data_short$PARTY)
political_data_short$ID = paste0(political_data_short$PARTY, political_data_short$INCUMBENT, political_data_short$WINNER)
View(political_data_short)
unique(political_data_short$ID)
for(i in 1:length(unique(political_data_short$ID))){
political_data_short$ID[political_data_short$ID==unique(political_data_short$ID)[i]] = 1
}
View(political_data_short)
political_data_short$ID = (political_data_short$WINNER)
political_data_short$PARTY = as.character(political_data_short$PARTY)
political_data_short$ID = paste0(political_data_short$PARTY, political_data_short$INCUMBENT, political_data_short$WINNER)
for(i in 1:length(unique(political_data_short$ID))){
political_data_short$ID[political_data_short$ID==unique(political_data_short$ID)[i]] = i
}
View(political_data_short)
for(i in 1:length(unique(political_data_short$ID))){
print(unique(political_data_short$ID))
print(i)
political_data_short$ID[political_data_short$ID==unique(political_data_short$ID)[i]] = i
}
political_data_short$ID = (political_data_short$WINNER)
political_data_short$PARTY = as.character(political_data_short$PARTY)
political_data_short$ID = paste0(political_data_short$PARTY, political_data_short$INCUMBENT, political_data_short$WINNER)
for(i in 1:length(unique(political_data_short$ID))){
print(unique(political_data_short$ID)[i])
print(i)
political_data_short$ID[political_data_short$ID==unique(political_data_short$ID)[i]] = i
}
?svm
names(political_data_short)
?sample
sample(20, 3)
k = 5
index = sample(nrow(political_data_short), nrow(political_data_short)*(k-1)/k)
train = political_data_short[index,]
test = political_data_short[-index,]
svm(ID~CANDTOTAL, data = train)
political_data_short$ID = as.numeric(political_data_short$ID)
k = 5
index = sample(nrow(political_data_short), nrow(political_data_short)*(k-1)/k)
train = political_data_short[index,]
test = political_data_short[-index,]
svm(ID~CANDTOTAL, data = train)
cv.pd = svm(ID~CANDTOTAL, data = train)
predict(object = cv.pd, newdata = test)
?predict
?svm
political_data_short$ID = as.factor(as.numeric(political_data_short$ID))
index = sample(nrow(political_data_short), nrow(political_data_short)*(k-1)/k)
train = political_data_short[index,]
test = political_data_short[-index,]
cv.pd = svm(ID~CANDTOTAL, data = train)
predict(object = cv.pd, newdata = test)
test.predictions == test$ID
test.predictions = predict(object = cv.pd, newdata = test)
mean(test.predictions == test$ID)
table(test.predictions, test$ID)
political_data_short$ID = as.factor(as.numeric(political_data_short$ID))
k = 5
for(i in 1:k){
index = sample(nrow(political_data_short), nrow(political_data_short)*(k-1)/k)
train = political_data_short[index,]
test = political_data_short[-index,]
cv.pd = svm(ID~CANDTOTAL, data = train)
test.predictions = predict(object = cv.pd, newdata = test)
table(test.predictions, test$ID)
}
k = 5
for(i in 1:k){
index = sample(nrow(political_data_short), nrow(political_data_short)*(k-1)/k)
train = political_data_short[index,]
test = political_data_short[-index,]
cv.pd = svm(ID~CANDTOTAL, data = train)
test.predictions = predict(object = cv.pd, newdata = test)
print(mean(test.predictions == test$ID))
}
table(test.predictions, test$ID)
?prop.test
prop.test(459, 980, correct = F)
